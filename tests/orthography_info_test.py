import unittest
from jkUnicode.orthography import OrthographyInfo, Orthography
from os.path import dirname, join


def get_font_path(filename="Empty-Regular.ttf"):
    return join(dirname(__file__), "data", filename)


def get_cmap():
    from fontTools.ttLib import TTFont

    return TTFont(get_font_path()).getBestCmap()


class TestOrthographyInfo(unittest.TestCase):
    def test_known_orthographies(self):
        o = OrthographyInfo()
        orthographies = [f"{ot.name}: {ot.code}" for ot in o.orthographies]
        assert orthographies == [
            "Afrikaans: af",
            "Aghem: agq",
            "Akan: ak",
            "Amharic: am",
            "Arabic (Morocco): ar",
            "Arabic: ar",
            "Assamese: as",
            "Asu: asa",
            "Asturian: ast",
            "Azeri (Cyrillic): az",
            "Azeri: az",
            "Basaa: bas",
            "Belarusian: be",
            "Bemba: bem",
            "Bena: bez",
            "Bulgarian: bg",
            "Bambara: bm",
            "Bangla: bn",
            "Tibetan: bo",
            "Breton: br",
            "Bodo: brx",
            "Bosnian (Cyrillic): bs",
            "Bosnian: bs",
            "Catalan: ca",
            "Chakma: ccp",
            "Chechen: ce",
            "Cebuano: ceb",
            "Chiga: cgg",
            "Cherokee: chr",
            "Kurdish, Sorani: ckb",
            "Czech: cs",
            "Welsh: cy",
            "Danish: da",
            "Taita: dav",
            "Swiss High German (Switzerland): de",
            "German: de",
            "Zarma: dje",
            "Dogri: doi",
            "Lower Sorbian: dsb",
            "Duala: dua",
            "Jola-Fonyi: dyo",
            "Dzongkha: dz",
            "Embu: ebu",
            "Ewe: ee",
            "Greek: el",
            "English (South Africa): en",
            "English: en",
            "Esperanto: eo",
            "Spanish: es",
            "Estonian: et",
            "Basque: eu",
            "Ewondo: ewo",
            "Dari (Afghanistan): fa",
            "Persian: fa",
            "Fulah (Adlam): ff",
            "Fulah: ff",
            "Finnish: fi",
            "Filipino: fil",
            "Faroese: fo",
            "Canadian French (Canada): fr",
            "French: fr",
            "Friulian: fur",
            "Western Frisian: fy",
            "Irish: ga",
            "Scottish Gaelic: gd",
            "Galician: gl",
            "Swiss German: gsw",
            "Gujarati: gu",
            "Gusii: guz",
            "Manx: gv",
            "Hausa (Niger): ha",
            "Hausa: ha",
            "Hawaiian: haw",
            "Hebrew: he",
            "Hindi: hi",
            "Hindi (Latin): hi",
            "Croatian: hr",
            "Upper Sorbian: hsb",
            "Hungarian: hu",
            "Armenian: hy",
            "Interlingua: ia",
            "Indonesian: id",
            "Igbo: ig",
            "Sichuan Yi: ii",
            "International Phonetic Alphabet: ipa",
            "Icelandic: is",
            "Italian: it",
            "Japanese: ja",
            "Ngomba: jgo",
            "Machame: jmc",
            "Javanese: jv",
            "Georgian: ka",
            "Kabyle: kab",
            "Kamba: kam",
            "Makonde: kde",
            "Kabuverdianu: kea",
            "Kaingang: kgp",
            "Koyra Chiini: khq",
            "Kikuyu: ki",
            "Kazakh: kk",
            "Kako: kkj",
            "Kalaallisut: kl",
            "Kalenjin: kln",
            "Khmer: km",
            "Kannada: kn",
            "Korean: ko",
            "Konkani: kok",
            "Kashmiri: ks",
            "Kashmiri (Devanagari): ks",
            "Shambala: ksb",
            "Bafia: ksf",
            "Colognian: ksh",
            "Kurdish: ku",
            "Cornish: kw",
            "Kirghiz: ky",
            "Langi: lag",
            "Luxembourgish: lb",
            "Ganda: lg",
            "Lakota: lkt",
            "Lingala: ln",
            "Lao: lo",
            "Northern Luri: lrc",
            "Lithuanian: lt",
            "Luba-Katanga: lu",
            "Luo: luo",
            "Luyia: luy",
            "Latvian: lv",
            "Maithili: mai",
            "Masai: mas",
            "Meru: mer",
            "Morisyen: mfe",
            "Malagasy: mg",
            "Makhuwa-Meetto: mgh",
            "Metaʼ: mgo",
            "Māori: mi",
            "Macedonian: mk",
            "Malayalam: ml",
            "Mongolian: mn",
            "Manipuri: mni",
            "Marathi: mr",
            "Malay: ms",
            "Maltese: mt",
            "Mundang: mua",
            "Myanmar Language: my",
            "Mazanderani: mzn",
            "Nama: naq",
            "North Ndebele: nd",
            "Low Saxon (Netherlands): nds",
            "Low German: nds",
            "Nepali: ne",
            "Dutch: nl",
            "Kwasio: nmg",
            "Norwegian Nynorsk: nn",
            "Ngiemboon: nnh",
            "Norwegian: no",
            "Nuer: nus",
            "Nyankole: nyn",
            "Oromo: om",
            "Odia: or",
            "Ossetic: os",
            "Punjabi (Perso-Arabic): pa",
            "Punjabi: pa",
            "Nigerian Pidgin: pcm",
            "Polish: pl",
            "Pushto (Pakistan): ps",
            "Pushto: ps",
            "Portuguese (European): pt",
            "Portuguese: pt",
            "Quechua: qu",
            "Romansh: rm",
            "Rundi: rn",
            "Romanian: ro",
            "Rombo: rof",
            "Russian: ru",
            "Kinyarwanda: rw",
            "Rwa: rwk",
            "Sanskrit: sa",
            "Sakha: sah",
            "Samburu: saq",
            "Santali: sat",
            "Sangu: sbp",
            "Sardinian: sc",
            "Sindhi: sd",
            "Sindhi (Devanagari): sd",
            "Sami, Northern: se",
            "Sena: seh",
            "Koyraboro Senni: ses",
            "Sango: sg",
            "Tachelhit: shi",
            "Tachelhit (Latin): shi",
            "Sinhala: si",
            "Slovak: sk",
            "Slovenian: sl",
            "Sami, Inari: smn",
            "Shona: sn",
            "Somali: so",
            "Albanian: sq",
            "Serbian: sr",
            "Serbian (Latin): sr",
            "Sundanese: su",
            "Swedish: sv",
            "Swahili (Congo): sw",
            "Swahili (Kenya): sw",
            "Swahili: sw",
            "Tamil: ta",
            "Telugu: te",
            "Teso: teo",
            "Tajik: tg",
            "Thai: th",
            "Tigrinya (Eritrea): ti",
            "Tigrinya: ti",
            "Turkmen: tk",
            "Tongan: to",
            "Turkish: tr",
            "Tatar: tt",
            "Tasawaq: twq",
            "Central Atlas Tamazight: tzm",
            "Uighur: ug",
            "Ukrainian: uk",
            "Urdu: ur",
            "Uzbek (Perso-Arabic): uz",
            "Uzbek (Cyrillic): uz",
            "Uzbek: uz",
            "Vai: vai",
            "Vai (Latin): vai",
            "Vietnamese: vi",
            "Vunjo: vun",
            "Walser: wae",
            "Wolof: wo",
            "Xhosa: xh",
            "Soga: xog",
            "Yangben: yav",
            "Yiddish: yi",
            "Yoruba (Benin): yo",
            "Yoruba: yo",
            "Nheengatu: yrl",
            "Chinese, Cantonese: yue",
            "Chinese, Cantonese (Simplified Han): yue",
            "Standard Moroccan Tamazight: zgh",
            "Chinese, Mandarin: zh",
            "Traditional Mandarin Chinese (Traditional Han): zh",
            "Zulu: zu",
        ]

    def test_scan_full(self):
        o = OrthographyInfo()
        o.cmap = get_cmap()
        supported = o.get_supported_orthographies(full_only=True)
        orthographies = [f"{ot.name}: {ot.code}" for ot in supported]
        assert orthographies == [
            "Asu: asa",
            "Bemba: bem",
            "Bena: bez",
            "Chiga: cgg",
            "Taita: dav",
            "Jola-Fonyi: dyo",
            "Embu: ebu",
            "Friulian: fur",
            "Gusii: guz",
            "Machame: jmc",
            "Javanese: jv",
            "Kamba: kam",
            "Makonde: kde",
            "Kikuyu: ki",
            "Kalenjin: kln",
            "Shambala: ksb",
            "Cornish: kw",
            "Ganda: lg",
            "Luo: luo",
            "Luyia: luy",
            "Meru: mer",
            "Morisyen: mfe",
            "Malagasy: mg",
            "Makhuwa-Meetto: mgh",
            "Māori: mi",
            "North Ndebele: nd",
            "Nyankole: nyn",
            "Oromo: om",
            "Rundi: rn",
            "Rombo: rof",
            "Kinyarwanda: rw",
            "Rwa: rwk",
            "Samburu: saq",
            "Sangu: sbp",
            "Sami, Northern: se",
            "Sena: seh",
            "Sango: sg",
            "Sami, Inari: smn",
            "Shona: sn",
            "Teso: teo",
            "Vunjo: vun",
            "Xhosa: xh",
            "Soga: xog",
        ]

    def test_scan_base(self):
        o = OrthographyInfo()
        o.cmap = get_cmap()
        supported = o.get_supported_orthographies(full_only=False)
        orthographies = [f"{ot.name}: {ot.code}" for ot in supported]
        assert orthographies == [
            "Asu: asa",
            "Bemba: bem",
            "Bena: bez",
            "Chiga: cgg",
            "Taita: dav",
            "Jola-Fonyi: dyo",
            "Embu: ebu",
            "Friulian: fur",
            "Swiss German: gsw",
            "Gusii: guz",
            "Machame: jmc",
            "Javanese: jv",
            "Kamba: kam",
            "Makonde: kde",
            "Kikuyu: ki",
            "Kalaallisut: kl",
            "Kalenjin: kln",
            "Shambala: ksb",
            "Cornish: kw",
            "Ganda: lg",
            "Luo: luo",
            "Luyia: luy",
            "Meru: mer",
            "Morisyen: mfe",
            "Malagasy: mg",
            "Makhuwa-Meetto: mgh",
            "Māori: mi",
            "North Ndebele: nd",
            "Nyankole: nyn",
            "Oromo: om",
            "Romansh: rm",
            "Rundi: rn",
            "Rombo: rof",
            "Kinyarwanda: rw",
            "Rwa: rwk",
            "Samburu: saq",
            "Sangu: sbp",
            "Sami, Northern: se",
            "Sena: seh",
            "Sango: sg",
            "Sami, Inari: smn",
            "Shona: sn",
            "Teso: teo",
            "Vunjo: vun",
            "Walser: wae",
            "Xhosa: xh",
            "Soga: xog",
        ]

    def test_scan_minimal(self):
        o = OrthographyInfo()
        o.cmap = get_cmap()
        supported = o.get_supported_orthographies_minimum()
        orthographies = [f"{ot.name}: {ot.code}" for ot in supported]
        assert orthographies == [
            "Breton: br",
            "Czech: cs",
            "Welsh: cy",
            "Danish: da",
            "Swiss High German (Switzerland): de",
            "German: de",
            "Lower Sorbian: dsb",
            "English (South Africa): en",
            "English: en",
            "Spanish: es",
            "Estonian: et",
            "Basque: eu",
            "Finnish: fi",
            "Canadian French (Canada): fr",
            "French: fr",
            "Irish: ga",
            "Scottish Gaelic: gd",
            "Galician: gl",
            "Hindi (Latin): hi",
            "Upper Sorbian: hsb",
            "Hungarian: hu",
            "Interlingua: ia",
            "Indonesian: id",
            "Italian: it",
            "Kabuverdianu: kea",
            "Kaingang: kgp",
            "Colognian: ksh",
            "Kurdish: ku",
            "Luxembourgish: lb",
            "Low German: nds",
            "Norwegian Nynorsk: nn",
            "Norwegian: no",
            "Portuguese (European): pt",
            "Portuguese: pt",
            "Quechua: qu",
            "Sardinian: sc",
            "Slovak: sk",
            "Slovenian: sl",
            "Sundanese: su",
            "Turkish: tr",
            "Nheengatu: yrl",
            "Zulu: zu",
        ]

    def test_almost_supported(self):
        # Check which orthographies are missing at most 3 characters
        o = OrthographyInfo()
        o.cmap = get_cmap()
        supported = o.get_almost_supported(3)
        orthographies = [f"{ot.name}: {ot.code}" for ot in supported]
        assert orthographies == [
            "Catalan: ca",
            "Zarma: dje",
            "Hawaiian: haw",
            "Igbo: ig",
            "Koyra Chiini: khq",
            "Lakota: lkt",
            "Metaʼ: mgo",
            "Koyraboro Senni: ses",
            "Tongan: to",
            "Tasawaq: twq",
            "Uzbek: uz",
        ]

    def test_single_orthography(self):
        # Info about one orthography
        o = OrthographyInfo()
        ot = o.orthography("en", "DFLT", "ZA")
        assert ot.name == "English (South Africa)"
        assert ot.unicodes_base == {
            65,
            66,
            67,
            68,
            69,
            70,
            71,
            72,
            73,
            74,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            87,
            88,
            89,
            90,
            97,
            98,
            99,
            100,
            101,
            102,
            103,
            104,
            105,
            106,
            107,
            108,
            109,
            110,
            111,
            112,
            113,
            114,
            115,
            116,
            117,
            118,
            119,
            120,
            121,
            122,
        }

    def test_reverse(self):
        """
        Get orthographies that support a given codepoint.
        """
        o = OrthographyInfo()
        o.build_reverse_cmap()
        u = ord("ö")
        result1 = [ot.code for ot in o.get_orthographies_for_unicode(u)]
        assert result1 == [
            "af",
            "az",
            "cy",
            "de",
            "de",
            "et",
            "fi",
            "fy",
            "gsw",
            "hu",
            "is",
            "ksh",
            "nds",
            "nl",
            "nmg",
            "nus",
            "sg",
            "sv",
            "tk",
            "tr",
            "wae",
        ]

        result2 = [ot.code for ot in o.get_orthographies_for_unicode_any(u)]
        assert result2 == [
            "af",
            "ast",
            "az",
            "br",
            "ca",
            "cs",
            "cy",
            "da",
            "de",
            "de",
            "dsb",
            "ee",
            "en",
            "en",
            "es",
            "et",
            "eu",
            "fi",
            "fr",
            "fr",
            "fy",
            "gd",
            "gl",
            "gsw",
            "hsb",
            "hu",
            "ia",
            "id",
            "is",
            "it",
            "kea",
            "kgp",
            "ksh",
            "lb",
            "nds",
            "nds",
            "nl",
            "nmg",
            "nn",
            "no",
            "nus",
            "pl",
            "pt",
            "qu",
            "rm",
            "ro",
            "sc",
            "se",
            "sg",
            "sk",
            "sl",
            "smn",
            "su",
            "sv",
            "tk",
            "to",
            "tr",
            "uz",
            "wae",
            "yrl",
            "zu",
        ]
